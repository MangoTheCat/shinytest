---
title: "Getting started with shinytest"
author: "Winston Chang"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```


## Why test Shiny applications?

After you get your Shiny application to a state where it works, it's often useful to have an automated system that checks that it continues to work as expected. There are many possible reasons for an application to stop working. These reasons include:

* An ugpraded R package has different behavior. (This could include Shiny itself!)
* You make modifications to your application.
* An external data source stops working, or returns data in a changed format.

One way to detect these problems is with manual testing -- in other words, by having a person interact with the app in a browser -- but this can be time-intensive, inconsistent, and imprecise. Having automated tests can alert you to these kinds of problems quickly and with almost zero effort, after the tests have been created.


## How testing works with shinytest

The **shinytest** package provides tools for creating and running automated tests on Shiny applications.

Shinytest uses snapshot-based testing strategy. The first time it runs a set of tests for an application, it performs some scripted interactions with the app and takes one or more snapshots of the application's state. These snapshots are saved to disk so that future runs of the tests can compare their results to them.

To create tests, the easiest method is to use the `recordTest()` function. This launches the application in a web browser and records your interactions with the application. These interactions are saved in a .R file, and are run using the strategy described above.


## Getting started


**Shinytest** is in active development:

```{r}
library(devtools)
install_github("rstudio/webdriver")
install_github("rstudio/shinytest")
```


### Recording tests

This is the general procedure for recording tests:

* Run `recordTest()` to launch the app in a test recorder.
* Create the tests by interacting with the application and telling the recorder to snapshot the state at various points.
* Quit the test recorder. When you do this, three things will happen:
  * The test script will be saved in a .R file in a subdirectory of the application named `tests/`.
  * If you are running in the RStudio IDE, it will automatically open this file in the editor.
  * The test script will be run, and the snapshots will be saved in a subdirectory of the `tests/` directory.

To record tests, run the following:

```{r}
library(shinytest)

# Launch the target app (replace with the correct path)
recordTest("path/to/app")
```

In a separate R process, this launches the Shiny application to be tested. We'll refer to this as the **target app**. This also launches a special Shiny application in the current R process which displays the target app in an iframe and has some controls outside the iframe. We'll refer to this as the **recorder app**. You will see something like this:

![](screenshot-recorder-1.png)

On the left is the target app (in this case, the "Shiny Widgets Gallery"), and on the right is the recorder app (titled "Test event recorder"). Note that you may need to make the browser window wider because the recorder panel occupies some space.

The panel on the right displays some controls for the test recorder, as well as a list of **Recorded events**. As you interact with the target app -- in other words, when you set inputs on the app -- you will see those interactions recorded in the Recorded events list.

For testing a Shiny application, setting inputs is only one part. It's also necessary to check that the application produces the correct outputs. This is accomplished by taking snapshots of the application's state.

There are two ways to record output values. One way is to take a **snapshot** of the application's state. This will record all input values, output values, and *exported* values (more on exported values later). To do this, click the "Take snapshot" button on the recorder app.

After modifying some inputs and taking a snapshot, it will look something like this:

![](screenshot-recorder-2.png)

It is also possible to take a *target* snapshot. This is a snapshot of on or more specified output (instead of the default, which is to snapshot the entire application). To do this, hold down the Control (or Command) button on your keyboard and click on an output; it will snapshot just that one output.


When you are done recording a sequence of events, click on the "Save script and exit test event recorder" button. If you are in the RStudio IDE, it will open the test script in the `tests/` subdirectory of the application. In this case, the name of the script is `mytest.R`:

```{r}
app <- ShinyDriver$new("..")
app$snapshotInit("mytest")

app$snapshot()
app$setInputs(checkGroup = c("1", "2"))
app$setInputs(checkGroup = c("1", "2", "3"))
app$setInputs(action = "click")
app$snapshot()
```

### Running tests

When you quit the test recorder, it will automatically run the test script. There are three separate components involved in running the tests:

1. First is the **test driver**. This is the R process that coordinates the testing and controls the web browser. When working on creating tests interactively, this is the R process that you use.

1. Next is the **Shiny process**, also known as the **server**. This is the R process that runs the target Shiny application.

1. Finally, there is the **web browser**, also known as the **client**, which connects to the server. This is a headless web browser -- one which renders the web page internally, but doesn't display the content to the screen ([PhantomJS](http://phantomjs.org/)).

When you exit the test recorder, it will by default automatically run the test script, and will print something like this:

```
Saved test code to /path/to/app/tests/mytest.R
Running mytest.R 
====== Comparing mytest.R ======
  No existing snapshots at mytest-expected/. This is a first run of tests.

Updating baseline snapshot at tests/mytest-expected
Renaming tests/mytest-current
      => tests/mytest-expected.
```

Behind the scenes, it runs `testApp()`. You can manually run the tests with this:

```{r}
testApp("myshinyapp", "mytest")
```

This will play back the interactions and record snapshots, as specified in the test script. The very first time the tests are run, they will be saved in a subdirectory of the app called `tests/mytest-expected`. These are the expected results, and future test runs will be compared against them.

The directory will contain two files for each snapshot. For exmaple:

```
001.json
001.png
```

The .json file is a JSON representation of the state of the application when `app$snapshot()` was called. The .png file is a screenshot of the application, which you can look at to inspect the state of the application.

The JSON file stores the state of all the input, output, and export values at the time of the snapshot:

```json
{
  "input": {
    "action": 1,
    "checkbox": true,
    "checkGroup": ["1", "2", "3"],
    "date": "2014-01-01",
    "dates": ["2014-01-01", "2015-01-01"],
    "file": null,
    "num": 1,
    "radio": "1",
    "select": "1",
    "slider1": 50,
    "slider2": [25, 75],
    "text": "Enter text..."
  },
  "output": {
    "actionOut": "[1] 1\nattr(,\"class\")\n[1] \"integer\"                \"shinyActionButtonValue\"",
    "checkboxOut": "[1] TRUE",
    "checkGroupOut": "[1] \"1\" \"2\" \"3\"",
    "dateOut": "[1] \"2014-01-01\"",
    "datesOut": "[1] \"2014-01-01\" \"2015-01-01\"",
    "fileOut": "NULL",
    "numOut": "[1] 1",
    "radioOut": "[1] \"1\"",
    "selectOut": "[1] \"1\"",
    "slider1Out": "[1] 50",
    "slider2Out": "[1] 25 75",
    "textOut": "[1] \"Enter text...\""
  },
  "export": {}
}
```

If you are using a source control system (like git), you should check in the expected results.


### Subsequent test runs

After the initial test run, you can run the tests again in the future to check for changes in your application's behavior. If there are no changes to the snapshots, you will just see something like this, with no additional output:

```
> testApp("path/to/app")
Running mytest.R 
====== Comparing mytest ======
```

The results are saved to `tests/mytest-current`, and compared against the saved results in `tests/mytest-expected`. If the results are exactly the same, then the test is considered successful. It will return to the console with no additional output, and delete the `tests/mytest-current` directory.


If there are any differences between the current and expected results, you'll see output like this:

```
Running mytest.R 
====== Comparing mytest ======
  Differences detected between mytest-current/ and mytest-expected/:

    Name         Status      
    001.json  != Files differ
    001.png   != Files differ
Would you like to view the differences between expected and current results [y/n]? 
```

If you press `y` and then Enter, it will open a Shiny application which shows the differences between the expected and current results. For screenshots, the differences will be highlighted in red. You can also choose different ways of viewing the differences in screenshots. It will look something like this:

![](diffviewer.png)

After inspecting the changes, you can choose to update the expected results (that is, replace the old expected results with the new current results), or to just quit without updating.

You should update the results if the changes are expected. You should quit without updating if the changes are unexpected.

If you want to compare the results again in the future, without running `testApp()`, you can run the following:

```{r}
snapshotCompare("path/to/app/", "mytest")
```


### Multiple test scripts

In the example above, we had a single test script, named `mytest.R`. If you want to have more than one set of tests for an application, you can record new tests, each with a different name. You can enter the name when recording your tests:

![](screenshot-recorder-name.png)


When you run `testApp("path/to/app")`, it will run all the tests scripts in the application's `tests/` directory.


## Testing in depth

### Customizing test scripts

The test recorder is the easiest way to create test scripts, but it is not the only way. You can create and edit test scripts manually.

A test script has this basic structure: first, there is an initialization, then the tests, and finally the tests are wrapped up.

In the initialization, the script creates a new ShinyDriver object and tells it what name to use for this set of tests.

```{r}
# Initialize a ShinyDriver object using the app in the test script's parent
# directory
app <- ShinyDriver$new("..")
app$snapshotInit("mytest")
```

Next, it defines some interactions with the application and takes snapshots.

```{r}
app$setInputs(checkGroup = c("1", "2"))
app$setInputs(checkGroup = c("1", "2", "3"))
app$setInputs(action = "click")
app$snapshot()

app$setInputs(action = "click")
app$snapshot()
```

For customizing a script, the second portion -- the interactions and snapshots -- is the part you will want to modify. For snapshot-based testing, there are two methods that are used: `app$setInputs()` and `app$snapshot()`.

#### Setting inputs with `app$setInputs()`

With `app$setInputs()`, you provide the name of one or more inputs and corresponding values to set them to. Consider this set of directives:

```{r}
app$setInputs(checkGroup = c("1", "2"))
app$setInputs(checkGroup = c("1", "2", "3"))
app$setInputs(action = "click")
```

Notice that we set the value of `checkGroup` two times in a row. When we recorded this test script, it started with the value `"1"`, and then we checked the `"2"` and `"3"` boxes. The recorded script set the value to `c("1", "2")`, and then ` c("1", "2", "3")`. The `c("1", "2")` value was simply an intermediate step.

It's possible to simplify and speed up the tests by dropping the intermediate step, which leaves us with this:

```{r}
app$setInputs(checkGroup = c("1", "2", "3"))
app$setInputs(action = "click")
```

And it's also possible to set `action` in the same call, resulting in this:

```{r}
app$setInputs(
  checkGroup = c("1", "2", "3"),
  action = "click"
)
```

This will set the values of inputs simultaneously, which will make the tests run faster.

This is because, when `app$setInputs()` is called, it normally returns control and moves on to the next step only after the server sends a response to the client.

The reason it waits for a response is so that a subsequent call to `app$snapshot()` will be sure to capture the updated output values. If `app$setInputs()` did not wait for a update, then, if the output update did not happen very quickly, a snapshot might capture the state of the application before the outputs are updated.

Because `app$setInputs()` waits for an update each time, it is faster to set multiple inputs in a single call to `app$setInputs()` than it is to have multiple calls to `app$setInputs()`.

Note: In versions of Shiny before 1.0.3.9000, calls to `app$setInputs()` which did not result in an output value change would timeout, and print a message about setting a longer timeout or calling `setInputs(wait_ = FALSE, values_ = FALSE)`. This is because those versions of Shiny did not send a response when no output values changed. As of Shiny 1.0.3.9000, when in testing mode, Shiny always sends a response to input changes, even if no output values have changed, so this message should no longer appear.


#### Taking snapshots with `app$snapshot()`

There are two ways to use `app$snapshot()`. The simplest way is to call it with no arguments:

```{r}
app$snapshot()
```

The first time this is called in a test script, it will record all input, output, and exported values from the application, in a file called `001.json`. The next call will save the values in `002.json`, and so on.

Each time you call `app$snapshot()`, it will also save a **screen shot** of the web browser, in a file `001.png`, `002.png`, and so on. These screen shots are useful for debugging your tests and inspecting what they're doing. You can tell it to not take screen shots, to save space and make the tests run slightly faster, in the initialization step, with:

```{r}
app$snapshotInit("mytest", screenshot = FALSE)
```

If you want to disable screenshots for a single snapshot, you can use:

```{r}
app$snapshot(screenshot = FALSE)
```

If you want more targeted tests, you can snapshot specific items with the `items` argument. For example, to capture the value of just the outputs named `"a"` and `"b"`, you would call:

```{r}
app$snapshot(items = list(output = c("a", "b")))
```

The value passed to `items` is a named list, where the `output` is a character vector with the names of outputs to snapshot. You could also capture specific inputs or exports:

```{r}
app$snapshot(items = list(
  input = "n",
  output = c("a", "b"),
  export = c("e1", "e2")
))
```

Finally, if you want to snapshot all outputs but no inputs or exports, you can simply set `output` to `TRUE`:

```{r}
app$snapshot(items = list(output = TRUE))
```

The same can be used to snapshot all inputs and/or all exports. To capture all outputs and exports, but no inputs:

```{r}
app$snapshot(items = list(output = TRUE, export = TRUE))
```


### Debugging test scripts

If you need to debug a test script, you can run line-by-line from the R console. However, you likely will have modify the first line. It normally will refer to the Shiny application the parent directory (`".."`):

```{r}
app <- ShinyDriver$new("..")
```

When the test is run the usual way, with `testApp()`, it will be run with the test directory as the working directory. However, when you run the tests from the command line, you generally will have a different working directory. To run the tests from a different directory, you will have to pass in the path to the application. It can be a relative path, for example:

```{r}
app <- ShinyDriver$new("path/to/app")
```

The rest of the test script can be run unchanged.


#### Screenshots

As you step through the script, you can inspect the state of the application in a few different ways. One is to view a screenshot. You should not to call `app$snapshot()` to get a screenshot, because it will increment the snapshot counter and shift the numbers of snapshots that really are part of the tests (e.g., snapshot 003 would become 004). Instead you can do this:

```{r}
app$take_screenshot()
```

This will display the screenshot as if it were a plot. (In RStudio, it will show in the Viewer pane.) You can inspect the screenshot to see the state of the application.


#### Getting input, output, and export values

It can also be useful to get the current input, output, and export values. As with screenshots, this is something that `app$snapshot()` does, but we don't want to call that function because increments the snapshot counter.

To fetch all values, you can call `app$getAllValues()`. This returns a list, which you can inspect with the `str()` function. It may look something like this:

```{r}
vals <- app$getAllValues()

str(vals)
#> List of 3
#>  $ input :List of 4
#>   ..$ action    :Classes 'integer', 'shinyActionButtonValue'  int 0
#>   ..$ checkbox  : logi TRUE
#>   ..$ checkGroup: chr "1"
#>   ..$ text      : chr "Enter text..."
#>  $ output:List of 12
#>   ..$ actionOut    : chr "[1] 0\nattr(,\"class\")\n[1] \"integer\"                #> \"shinyActionButtonValue\""
#>   ..$ checkboxOut  : chr "[1] TRUE"
#>   ..$ checkGroupOut: chr "[1] \"1\""
#>   ..$ textOut      : chr "[1] \"Enter text...\""
#>  $ export: Named list()
```

The same data is returned (invisibly) from each call to `app$setInput()`, so you can also look at the return value from those function calls to get the same result.

The values retrieved this way can be used for expectation-based testing. For example, if you are using the **testthat** package for testing you could do something like:

```{r}
vals <- app$getAllValues()
# Another option: save values when setting input values
# vals <- app$setInputs(checkbox = TRUE)

expect_identical(vals$output$checkboxOut, "[1] TRUE")
```
